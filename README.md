#  ETL-pipeline для построения отчетности продаж

## Описание

Этот проект реализует ETL-пайплайн для обработки и построения отчетов по продажам зданий. Он извлекает данные из источников, преобразует их с помощью заданной бизнес-логики и загружает в целевые базы данных или витрины, позволяя удобно анализировать продажи.

## Основные возможности

- Извлечение данных из MariaDB (или других источников)
- Сложные SQL-запросы с иерархиями и фильтрацией
- Обработка результатов с использованием pandas
- Загрузка обработанных данных в ClickHouse с поддержкой партиционирования и обновления
- Автоматизация с помощью Apache Airflow для ежедневного запуска

## Технологии и инструменты

- Python 3.x
- Apache Airflow (DAGs и операторы Python)
- MariaDB (источник данных)
- ClickHouse (хранилище данных)
- pandas (обработка данных)
- airflow_clickhouse_plugin (интеграция с ClickHouse)
- pendulum (работа с датами и таймзонами)
- Docker и Docker Compose (контейнеризация и оркестрация)

## Структура проекта

- `dags/` — Airflow DAGs с ETL процессами
- `docker/` — архивы файлов и образов для Docker контейнеров
- `scripts/` - SQL-скрипт с подробными комментариями, на основе которого создаётся витрина
- `README.md` — документация проекта

## Установка и запуск через Docker Compose

1. Клонируйте репозиторий:
git clone https://github.com/Alina-Bagaeva/Project_ETL-pipeline_for_building_sales_reports.git
cd Project_ETL-pipeline_for_building_sales_reports

2. Убедитесь, что у вас установлены Docker и Docker Compose.

3. Запустите сборку и поднятие сервисов:
docker-compose up -d

4. Проверьте состояние контейнеров:
docker-compose ps

5. Для остановки и удаления контейнеров, сети и томов выполните:
docker-compose down

## Настройка

- Конфигурация подключения к MariaDB и ClickHouse задаётся в переменных окружения для контейнеров или в настройках Airflow.
- При необходимости измените параметры в `docker-compose.yml` или `.env` файлах.

## Описание DAG-ов

| Название DAG                        | Назначение                                                                                      | Особенности                                                                                         |
|-----------------------------------|------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|
| mariadb_to_clickhouse_ROP1         | Формирование витрины данных за период от 2025-01-01 до 2025-07-31                               | Используется для исторической загрузки большого объема данных                                      |
| mariadb_to_clickhouse_ROP1_daily   | Ежедневное дополнение и обновление витрины данными за вчерашний день                           | Запускается регулярно (например, в 8:00 по Москве) для актуализации данных в ClickHouse             |

---

Таким образом, система ETL содержит два разных DAG-а, обеспечивающих как начальную загрузку данных, так и их ежедневное обновление, что является стандартной практикой при работе с аналитическими витринами.
## Контакты

Для вопросов и предложений контакты: kraeva.alina@mail.ru

---

*Этот README содержит инструкции по работе с Docker Compose для запуска проекта в контейнерах, ускоряя деплой и облегчая управление зависимостями.*
